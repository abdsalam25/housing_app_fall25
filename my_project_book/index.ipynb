{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/utils.py:177: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance.\n",
            "  return FileStore(store_uri, store_uri)\n",
            "2025/12/15 17:27:51 INFO mlflow.tracking.fluent: Experiment with name 'Churn_Model_Exp' does not exist. Creating a new experiment.\n",
            "2025/12/15 17:27:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DagsHub Creds set. Loading data...\n",
            "Data loaded from CSV.\n",
            "Training Complete! F1 Score: 0.5263157894736842\n",
            "SUCCESS: model.joblib saved to project root.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import mlflow\n",
        "import dagshub\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "dagshub.init(repo_owner='abdsalam25', repo_name='churn-project', mlflow=True)\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(\"../churn_data.csv\")\n",
        "except:\n",
        "    df = pd.read_csv(\"churn_data.csv\")\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "features = ['gender', 'SeniorCitizen', 'tenure', 'MonthlyCharges', 'Partner', 'Dependents', 'PhoneService']\n",
        "X = df[features]\n",
        "y = df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "cleaner = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), ['tenure', 'MonthlyCharges']),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService'])\n",
        "])\n",
        "\n",
        "models_config = {\n",
        "    \"Ridge\": {\n",
        "        \"model\": RidgeClassifier(),\n",
        "        \"params\": {\"model__alpha\": [0.1, 1.0]}\n",
        "    },\n",
        "    \"GradientBoosting\": {\n",
        "        \"model\": GradientBoostingClassifier(),\n",
        "        \"params\": {\"model__n_estimators\": [50], \"model__learning_rate\": [0.1]}\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
        "        \"params\": {\"model__n_estimators\": [50], \"model__max_depth\": [3]}\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"model\": LGBMClassifier(verbose=-1),\n",
        "        \"params\": {\"model__n_estimators\": [50]}\n",
        "    }\n",
        "}\n",
        "\n",
        "experiment_id = 1\n",
        "\n",
        "for model_name, config in models_config.items():\n",
        "    for use_pca in [False, True]:\n",
        "        for use_tuning in [False, True]:\n",
        "            \n",
        "            run_name = f\"Exp{experiment_id}_{model_name}_PCA-{use_pca}_Tuned-{use_tuning}\"\n",
        "            print(f\"Running {run_name}...\")\n",
        "            \n",
        "            mlflow.set_experiment(\"Final_Project_Experiments\")\n",
        "            with mlflow.start_run(run_name=run_name):\n",
        "                \n",
        "                steps = [('preprocessor', cleaner)]\n",
        "                if use_pca:\n",
        "                    steps.append(('pca', PCA(n_components=2)))\n",
        "                steps.append(('model', config[\"model\"]))\n",
        "                pipeline = Pipeline(steps)\n",
        "                \n",
        "                if use_tuning:\n",
        "                    model = GridSearchCV(pipeline, config[\"params\"], cv=3, scoring='f1_macro')\n",
        "                else:\n",
        "                    model = pipeline\n",
        "                \n",
        "                model.fit(X_train, y_train)\n",
        "                \n",
        "                if use_tuning:\n",
        "                    score = model.best_score_\n",
        "                    final_model = model.best_estimator_\n",
        "                else:\n",
        "                    score = cross_val_score(model, X_train, y_train, cv=3, scoring='f1_macro').mean()\n",
        "                    final_model = model\n",
        "                \n",
        "                mlflow.log_param(\"model\", model_name)\n",
        "                mlflow.log_param(\"pca\", use_pca)\n",
        "                mlflow.log_metric(\"cv_f1\", score)\n",
        "                \n",
        "                if experiment_id == 16:\n",
        "                    joblib.dump(final_model, \"../model.joblib\")\n",
        "                    print(\"Saved final model.\")\n",
        "\n",
        "            experiment_id += 1\n",
        "\n",
        "print(\"DONE! Check DagsHub now.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
