{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmSRGJ9R1kTi",
        "outputId": "20c1a54a-81c4-45e5-8bd0-f8a08cea6d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfaWlb492CvZ",
        "outputId": "74e2ca27-7257-41cc-e46a-14905665a684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/housing_fall2025\n"
          ]
        }
      ],
      "source": [
        "base_folder = \"/content/drive/MyDrive/Colab Notebooks/housing_fall2025\"\n",
        "%cd \"{base_folder}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7rUZ8BQ2kYL",
        "outputId": "22263b6f-bdb4-4ab5-c885-3bac96812bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== BUILDING 3NF SQLITE DATA MODEL ===\n",
            "\n",
            "[STEP 1] Loading CSV into DataFrame…\n",
            "[1] Checking for housing.tgz…\n",
            "[1a] File not found. Creating datasets/ and downloading dataset…\n",
            "[1b] Download completed.\n",
            "[2] Extracting housing.tgz…\n",
            "[3] Loading housing.csv into DataFrame…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1553684944.py:20: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  housing_tarball.extractall(path=\"datasets\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 20640 rows.\n",
            "\n",
            "[STEP 2] Creating surrogate key block_id…\n",
            "block_id added.\n",
            "\n",
            "[STEP 3] Building ocean_proximity dimension table…\n",
            "Found 5 unique ocean_proximity values.\n",
            "\n",
            "[STEP 4] Merging ocean_proximity_id into main DataFrame…\n",
            "\n",
            "[STEP 5] Creating 3NF DataFrames (ocean, block, stats)…\n",
            "3NF DataFrames created.\n",
            "\n",
            "[STEP 6] Creating SQLite database and tables…\n",
            "Running SQL schema creation script…\n",
            "Tables created.\n",
            "\n",
            "[STEP 7] Inserting data into SQLite database…\n",
            "Inserting ocean_proximity dimension…\n",
            "Inserting block table…\n",
            "Inserting block_housing_stats…\n",
            "\n",
            "=== DONE! SQLite DB created at: housing.db ===\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "def build_churn_database(db_path=\"project.db\"):\n",
        "    csv_path = \"churn_data.csv\"\n",
        "    if not os.path.exists(csv_path):\n",
        "        csv_path = \"../churn_data.csv\"\n",
        "    \n",
        "    if not os.path.exists(csv_path):\n",
        "        print(\"Error: churn_data.csv not found.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    demog_cols = ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents']\n",
        "    account_cols = [c for c in df.columns if c not in demog_cols or c == 'customerID']\n",
        "\n",
        "    if os.path.exists(db_path):\n",
        "        os.remove(db_path)\n",
        "    \n",
        "    conn = sqlite3.connect(db_path)\n",
        "\n",
        "    df[demog_cols].to_sql('demographics', conn, index=False)\n",
        "    df[account_cols].to_sql('accounts', conn, index=False)\n",
        "\n",
        "    query = \"\"\"\n",
        "    SELECT d.*, a.* \n",
        "    FROM demographics d \n",
        "    JOIN accounts a ON d.customerID = a.customerID\n",
        "    \"\"\"\n",
        "    \n",
        "    df_joined = pd.read_sql(query, conn)\n",
        "    \n",
        "    df_joined = df_joined.loc[:, ~df_joined.columns.duplicated()]\n",
        "\n",
        "    df_joined.to_csv(\"churn_data.csv\", index=False)\n",
        "    \n",
        "    if os.path.exists(\"../docker-compose.yml\"):\n",
        "        df_joined.to_csv(\"../churn_data.csv\", index=False)\n",
        "\n",
        "    print(\"Database built.\")\n",
        "    print(\"SQL Join performed.\")\n",
        "    print(\"Data saved to churn_data.csv ready for Part 2.\")\n",
        "    print(df_joined.head())\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "build_churn_database()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
